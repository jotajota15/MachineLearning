{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos:\n",
    "* Estudiante: Juan Jose Valverde Campos\n",
    "* Carnet: B47200\n",
    "* Laboratorio 3 - LR\n",
    "* Profesor: Pablo Sauma Chacón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este laboratorio se trabajará con el set de datos: fish_perch.csv que consiste de datos estrictamente numéricos. El objetivo de este set de datos es predecir el peso weight de cada pez en función de sus otros atributos: Length1, Length2, Length3, Width y Height. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from LR import LR # Clase implementada.\n",
    "from sklearn.model_selection import PredefinedSplit, train_test_split\n",
    "\n",
    "df =  pd.read_csv('fish_perch.csv',delimiter=\",\",decimal=\".\")\n",
    "Y = df.pop(\"Weight\")\n",
    "myLr = LR()\n",
    "def score(y_true, y_predict):\n",
    "    '''\n",
    "    Funcion de R cuadrado\n",
    "    '''\n",
    "    SSR = np.sum(np.power((y_true - y_predict),2)) # Sum of squared regression\n",
    "    SST = np.sum(np.power((y_true - np.mean(y_true)),2)) # Sum of squared total \n",
    "    return 1-SSR / SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para cada prueba calcule e imprima el error R2, realice la prueba con múltiples combinaciones de parámetros, intentando mejorar la estimación\n",
    "\n",
    "Nota: En este caso se presentan combinaciones con parámetros que ya previamente se detectó que dan buenos resultados, a excpeción de la prueba 0, que corresponde a la inicialización de todos los hiperparámetros dados por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba 0.  -1.833386347214416e+130\n",
      "Prueba 1.  0.8783435198809615\n",
      "Prueba 2.  0.9114086725602027\n",
      "Prueba 3.  0.9113760047857967\n",
      "Prueba 4.  0.8265941633208307\n",
      "Prueba 5.  0.8458441123215248\n",
      "Prueba 6.  0.9341589552760945\n",
      "Prueba 7.  0.9148094063118365\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, train_size=0.75, test_size=0.25, random_state=21)\n",
    "\n",
    "# Prueba 0\n",
    "myLr.fit(X_train, y_train)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 0. \",score(y_test,y_pred))\n",
    "# Prueba 1\n",
    "myLr.fit(X_train, y_train,max_epochs=100000, threshold=0.000001,learning_rate=0.0001,momentum=1e-2, decay=1e-5, error = 'mse', regularization='l2', lamda=1e-3)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 1. \",score(y_test,y_pred))\n",
    "# Prueba 2\n",
    "myLr.fit(X_train, y_train,max_epochs=10000000, threshold=0.0000001,learning_rate=0.0001,momentum=1e-2, decay=0, error = 'mse', regularization='elastic-net', lamda=1e-3)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 2. \",score(y_test,y_pred))\n",
    "# Prueba 3\n",
    "myLr.fit(X_train, y_train,max_epochs=10000000, threshold=0.0000001,learning_rate=0.0001,momentum=1e-3, decay=0, error = 'mse', regularization='elastic-net', lamda=1e-3)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 3. \",score(y_test,y_pred))\n",
    "# Prueba 4\n",
    "myLr.fit(X_train, y_train,max_epochs=100000, threshold=0.000000001,learning_rate=1e-2,momentum=0.99, decay=1e-5, error = 'mae', regularization='l1', lamda=1e-4)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 4. \",score(y_test,y_pred))\n",
    "# Prueba 5\n",
    "myLr.fit(X_train, y_train,max_epochs=1000000, threshold=0.000000001,learning_rate=1e-1,momentum=0.99, decay=1e-6, error = 'mae', regularization='l1', lamda=1e-2)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 5. \",score(y_test,y_pred))\n",
    "# Prueba 6\n",
    "myLr.fit(X_train, y_train,max_epochs=1000000, threshold=0.000000001,learning_rate=1e-1,momentum=0.50, decay=1e-6, error = 'mae', regularization='l1', lamda=1e-2)\n",
    "y_pred = myLr.predict(X_test)\n",
    "print(\"Prueba 6. \",score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál fue la combinación de parámetros que le proveyó el mejor resultado?\n",
    "En este caso la combinación que dio mejores resultados corresponde:\n",
    "* A la combinación de la prueba 2 con un R2 reportado de 0.9114, para el caso de uso de función de error MSE.\n",
    "* A la combinación de la prueba 6 con un R2 reportado de 0.9341, para el caso de uso de función de error MAE.\n",
    "\n",
    "Dado lo anterior parece que el mejor modelo es el de la prueba 6 con un R2 reportado de 0.9341, no obstante para el siguiente segmento se utilizará también la combinación de la prueba 2, para ver que sucede según la semilla que se seleccione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué pasa si utiliza esa misma combinación pero cambia la semilla del train_test_split?  Pruebe con varias semillas\n",
    "* Nota: Se utiliza tres tipos de semilla distinta para cada uno de los casos [42,10,5]\n",
    "1. Los resultados muestran que según el tipo de semilla se tienen resultados distintos, donde por ejemplo según el tipo de semilla la función de error MSE supera a la función de error de MAE, contrario a lo que se tenía previamente (Donde hay que recordar que estos son otro más de los hiperparámetros del modelo).\n",
    "2. Además se observa que incluso el resultado en solo una de las semillas continúa con resultados por sobre el 90% en el R cuadrado, semilla = 5, como se tenían previamente. Lo que demuestra el impacto de la semilla seleccionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba de valor random =  42  con MSE:  0.8843046724780531\n",
      "Prueba de valor random =  42  con MAE:  0.8298235445615041\n",
      "Prueba de valor random =  10  con MSE:  0.7927893170495759\n",
      "Prueba de valor random =  10  con MAE:  0.8045185124638912\n",
      "Prueba de valor random =  5  con MSE:  0.950067726733323\n",
      "Prueba de valor random =  5  con MAE:  0.9167714874795835\n"
     ]
    }
   ],
   "source": [
    "randoms = [42,10,5]\n",
    "\n",
    "for random in randoms : \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, Y, train_size=0.75, test_size=0.25, random_state=random)\n",
    "    myLr.fit(X_train, y_train,max_epochs=10000000, threshold=0.0000001,learning_rate=0.0001,momentum=1e-3, decay=0, error = 'mse', regularization='elastic-net', lamda=1e-3)\n",
    "    y_pred = myLr.predict(X_test)\n",
    "    print(\"Prueba de valor random = \", random, \" con MSE: \",score(y_test,y_pred))\n",
    "    myLr.fit(X_train, y_train,max_epochs=1000000, threshold=0.000000001,learning_rate=1e-1,momentum=0.50, decay=1e-6, error = 'mae', regularization='l1', lamda=1e-2)\n",
    "    y_pred = myLr.predict(X_test)\n",
    "    print(\"Prueba de valor random = \", random, \" con MAE: \",score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si pasa algo inusual: ¿Por qué cree que pasa esto?\n",
    "Esto sucede por la forma que se realiza la separación de datos, lo cual provocan que datos de entrenamiento y datos de testing sean distintos según el tipo de semilla elegido. Esto provoca que los hiperparámetros del modelo elegido como el \"mejor\" pueda estar presentando un sesgo para un tipo de semilla específico (Un tipo de separación específico de entrenamiento y testing), lo que puede resolverse utilizando lo visto en clase de tener un tercer conjunto de datos de validación."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d3566b98539942dfe42f243b655841af5c597145eebc5638a47e844e4435e63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
